{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92504139-481a-4389-836f-80f2de7f117d",
   "metadata": {},
   "source": [
    "# Python script for Generating_md5 checksums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e5bc8-0b54-40c7-86fd-e180de36e573",
   "metadata": {},
   "source": [
    "### Date: Junly 29, 2024\n",
    "### Location: Emory University, Georgia, USA\n",
    "### By: Seyedeh Somayyeh Mousavi\n",
    "### Email: bmemousavi@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44c99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6215c-c589-463c-b2df-d65aa10be0ab",
   "metadata": {},
   "source": [
    "# Part 1: Setup and Initialization (Modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952c16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.1: Path containing the data (Change)\n",
    "Data_Input_Path = '../sample_data/'\n",
    "\n",
    "# Part 1.2: Path where the results will be saved (Change)\n",
    "Data_Output_Path = '../results/'\n",
    "\n",
    "# Part 1.3: Create the folder for MD5 Checksum records (Don't change)\n",
    "MD5_Checksum_Path = os.path.join(Data_Output_Path, 'MD5_Checksum_records_matlab') \n",
    "# Create the directory if it doesn't exist (Don't change)\n",
    "os.makedirs(MD5_Checksum_Path, exist_ok=True)\n",
    "\n",
    "# Part 1.4: List of files in the folder and subfolders (Change)\n",
    "data_endswith = '.mat' \n",
    "# (Don't change)\n",
    "Input_Data_list = []\n",
    "for root, dirs, files in os.walk(Data_Input_Path):\n",
    "    for file in files:\n",
    "        if file.endswith(data_endswith):\n",
    "            Input_Data_list.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae605f7-3dcc-4af2-bd6f-936e0e413e34",
   "metadata": {},
   "source": [
    "# Part 2: Validations (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e51b076-107a-40f5-9d4a-9c92a09d5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are no files in the input data list\n",
    "if not Input_Data_list:\n",
    "    raise ValueError('No signal files found in the Data_Input_Folder. Please check the folder and try again.')\n",
    "\n",
    "# Check if the Output_Path exists\n",
    "if not os.path.isdir(Data_Output_Path):\n",
    "    raise NotADirectoryError(f'Output_Path \"{Data_Output_Path}\" does not exist. Please check the folder path and try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba759ed-9881-4591-805a-c00164026c67",
   "metadata": {},
   "source": [
    "# Part 3: Parameter Configuration (Modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dada3796-97c8-45ad-9aad-d168aa223873",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {}\n",
    "\n",
    "# Define the function details that you will use in the next steps\n",
    "Params['function_dict'] = {\n",
    "    \n",
    "    # Fun_0: (Don't Change)\n",
    "    'Fun_0': {\n",
    "        'name': 'load', \n",
    "        'rel_path': '',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    },\n",
    "    # Fun_1 (Change)\n",
    "    'Fun_1': {\n",
    "        'name': 'peak_det_modified_pan_tompkins',\n",
    "        'rel_path': '../',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    },\n",
    "    # Fun_2 (Change)\n",
    "    'Fun_2': {\n",
    "        'name': 'max_values',\n",
    "        'rel_path': '../',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb9166-9c9b-4c3a-be85-a8b5bd2318b7",
   "metadata": {},
   "source": [
    "# Part 4.1: Generate_md5 checksums for functions (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f222200c-09b1-438c-b3c2-c77e10268ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Path is not a directory, \n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the MD5 checksum of a file\n",
    "def calculate_md5_for_file(file_path):\n",
    "    md5_hash = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5_hash.update(byte_block)\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "# Function to calculate a combined MD5 checksum for all files in a directory\n",
    "def calculate_md5_for_folder(folder_path):\n",
    "    md5_hash = hashlib.md5()\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Sorting to ensure consistent order\n",
    "        for file_name in sorted(files):  \n",
    "            file_path = os.path.join(root, file_name)\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "                    md5_hash.update(byte_block)\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "# Add MD5 checksum for each function based on rel_path\n",
    "for key, func_details in Params['function_dict'].items():\n",
    "    checksums = ''\n",
    "    path = func_details['rel_path']\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        # If the path is a directory, calculate MD5 for the whole directory\n",
    "        checksums = calculate_md5_for_folder(path)\n",
    "    elif os.path.isfile(path):\n",
    "        # If the path is a file, calculate MD5 for the file\n",
    "        checksums = calculate_md5_for_file(path)\n",
    "    else:\n",
    "        # Handle the case where the path is neither a file nor a directory\n",
    "        print(f\"Warning: Path is not a directory, {path}.\")\n",
    "        \n",
    "    func_details['codebase_md5chsum'] = checksums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307698b4-3fa0-424c-a95d-71e14cbd677b",
   "metadata": {},
   "source": [
    "# Save the Params (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a814579-9775-48e5-b846-29e11b1877fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params_function_dict has been saved as a CSV file to ../results/MD5_Checksum_records_matlab/Params_function_dict.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert the Params['function_dict'] dictionary to a list of dictionaries\n",
    "data = []\n",
    "for key, func_details in Params['function_dict'].items():\n",
    "    row = {\n",
    "        'function_key': key,\n",
    "        'name': func_details['name'],\n",
    "        'rel_path': func_details['rel_path'],\n",
    "        'codebase_git_repo': func_details['codebase_git_repo'],\n",
    "        'codebase_git_commit_id': func_details['codebase_git_commit_id'],\n",
    "        'codebase_md5chsum': func_details['codebase_md5chsum']\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "csv_path = os.path.join(MD5_Checksum_Path, \"Params_function_dict.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Params_function_dict has been saved as a CSV file to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab807a-170b-41bd-a87b-e8af31558e13",
   "metadata": {},
   "source": [
    "# Part 4.2: Generate_md5 checksums for records (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62535bc-e396-4ae3-bb5e-995331582922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating MD5 for A0003.mat\n",
      "Generating MD5 for A0004.mat\n",
      "Generating MD5 for A0005.mat\n",
      "Generating MD5 for A0006.mat\n",
      "Generating MD5 for A0007.mat\n",
      "Generating MD5 for A0008.mat\n",
      "Generating MD5 for A0009.mat\n",
      "Generating MD5 for A0010.mat\n",
      "Generating MD5 for A0001.mat\n",
      "Generating MD5 for A0002.mat\n"
     ]
    }
   ],
   "source": [
    "def generate_md5_for_record(file_path, output_path):\n",
    "    \n",
    "    # Create an MD5 hash object\n",
    "    hash_md5 = hashlib.md5()\n",
    "    \n",
    "    # Open the file in binary read mode\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        \n",
    "        # Read the file in chunks of 4096 bytes\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            # Update the MD5 hash object with the chunk\n",
    "            hash_md5.update(chunk)\n",
    "    \n",
    "    # Get the hexadecimal representation of the MD5 hash\n",
    "    md5_hash = hash_md5.hexdigest()\n",
    "    \n",
    "    # Open the output file in write mode\n",
    "    with open(output_path, \"w\") as out_file:\n",
    "        # Write the MD5 hash to the output file\n",
    "        out_file.write(md5_hash)\n",
    "    \n",
    "    # Return the MD5 hash\n",
    "    return md5_hash\n",
    "\n",
    "def generate_md5_for_all_records_in_folder(input_folder_path, results_folder_path):\n",
    "\n",
    "    results_folder_path = results_folder_path + \"MD5_Checksum_records_matlab\"\n",
    "    \n",
    "    # Walk through the directory tree starting from input_folder_path\n",
    "    for root, dirs, files in os.walk(input_folder_path):\n",
    "        \n",
    "        # Compute the relative path from the input folder path\n",
    "        relative_path = os.path.relpath(root, input_folder_path)\n",
    "        \n",
    "        # Create corresponding folder in the results directory\n",
    "        result_folder = os.path.join(results_folder_path, relative_path)\n",
    "        os.makedirs(result_folder, exist_ok=True)\n",
    "        \n",
    "        # Iterate over all files in the current directory\n",
    "        for filename in files:\n",
    "            \n",
    "            # Check if the file has the desierd extension\n",
    "            if filename.endswith(data_endswith):\n",
    "                \n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                # Construct the output file path\n",
    "                output_path = os.path.join(result_folder, f\"MD5_{os.path.splitext(filename)[0]}.txt\")\n",
    "                \n",
    "                # Print the filename being processed\n",
    "                print(f\"Generating MD5 for {filename}\")\n",
    "                \n",
    "                # Generate the MD5 hash for the file and save it\n",
    "                generate_md5_for_record(file_path, output_path)\n",
    "\n",
    "generate_md5_for_all_records_in_folder(Data_Input_Path, Data_Output_Path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
