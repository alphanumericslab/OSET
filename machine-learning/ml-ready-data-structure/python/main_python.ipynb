{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92504139-481a-4389-836f-80f2de7f117d",
   "metadata": {},
   "source": [
    "# General template of Python script for extracting features using various functions from signals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e5bc8-0b54-40c7-86fd-e180de36e573",
   "metadata": {},
   "source": [
    "### Date: June 19, 2024\n",
    "### Location: Emory University, Georgia, USA\n",
    "### By: Seyedeh Somayyeh Mousavi\n",
    "### Email: bmemousavi@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44c99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from extract_feature import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6215c-c589-463c-b2df-d65aa10be0ab",
   "metadata": {},
   "source": [
    "# Part 1: Setup and Initialization (Modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952c16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.1: Path containing the data (Change)\n",
    "Data_Input_Path = '../sample_data/'\n",
    "\n",
    "# Part 2.2: Path where the results will be saved (Change)\n",
    "Data_Output_Path = '../results/'\n",
    "\n",
    "# Part 2.3: Name of the output file (Change)\n",
    "Desired_Output_File = 'Example_ECG_ML_Ready_Python.json'\n",
    "\n",
    "# Part 2.4: List of files in the folder and subfolders (Change)\n",
    "data_endswith = '.mat'\n",
    "\n",
    "# Don't change\n",
    "Input_Data_list = []\n",
    "for root, dirs, files in os.walk(Data_Input_Path):\n",
    "    for file in files:\n",
    "        if file.endswith(data_endswith):\n",
    "            Input_Data_list.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb2348-eabd-4086-818c-a1584b8e90be",
   "metadata": {},
   "source": [
    "# Part 2: Parameter Configuration (Modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc846046-2bb0-4242-a4ae-bf0be3ee138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {}\n",
    "\n",
    "# Part 1.1: Sampling frequency (Hz) (Change)\n",
    "Params['Fs'] = 500.0\n",
    "\n",
    "# Part 1.2: Number of channels in the dataset (Change)\n",
    "Params['Number_Channels'] = 12\n",
    "\n",
    "# Part 1.3: Powerline frequency (Hz) (Change)\n",
    "Params['Powerline_frequency'] = 60\n",
    "\n",
    "# Part 1.4: Define the function details that you will use in the next steps\n",
    "Params['function_dict'] = {\n",
    "    \n",
    "    # Fun_0: (Don't Change)\n",
    "    'Fun_0': {\n",
    "        'name': 'load', \n",
    "        'rel_path': '',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    },\n",
    "    # Fun_1 (Change)\n",
    "    'Fun_1': {\n",
    "        'name': 'frequency_domain_features',\n",
    "        'rel_path': '../',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    },\n",
    "    # Fun_2 (Change)\n",
    "    'Fun_2': {\n",
    "        'name': 'Extremum_values',\n",
    "        'rel_path': '../',\n",
    "        'codebase_git_repo': '',\n",
    "        'codebase_git_commit_id': ''\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac1990-90f4-4b7b-a395-1054c0a3c152",
   "metadata": {},
   "source": [
    "# Part 3: Validations (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fb6c77-d284-49b6-b432-4091408cc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are no files in the input data list\n",
    "if not Input_Data_list:\n",
    "    raise ValueError('No signal files found in the Data_Input_Folder. Please check the folder and try again.')\n",
    "\n",
    "# Check if Fs is a numerical value\n",
    "if not isinstance(Params['Fs'], (int, float)):\n",
    "    raise ValueError('Fs must be a numerical value.')\n",
    "\n",
    "# Check if Number_channels is a numerical value \n",
    "if not isinstance(Params['Number_Channels'], (int, float)):\n",
    "    raise ValueError('Number of channels must be a numerical value.')\n",
    "\n",
    "# Check if the Output_Path exists\n",
    "if not os.path.isdir(Data_Output_Path):\n",
    "    raise NotADirectoryError(f'Output_Path \"{Data_Output_Path}\" does not exist. Please check the folder path and try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a1339-0c33-4b68-a0e7-9ffade0741b7",
   "metadata": {},
   "source": [
    "# Part 4.1: Generate_md5 checksums for functions (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9340d-0b47-49d3-a1dc-0f6a5da895ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generate_md5 checksums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31d4e31-71eb-4333-8101-c09f73a62c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  is neither a file nor a directory\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the MD5 checksum of a file\n",
    "def calculate_md5_for_file(file_path):\n",
    "    md5_hash = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5_hash.update(byte_block)\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "# Function to calculate a combined MD5 checksum for all files in a directory\n",
    "def calculate_md5_for_folder(folder_path):\n",
    "    md5_hash = hashlib.md5()\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Sorting to ensure consistent order\n",
    "        for file_name in sorted(files):  \n",
    "            file_path = os.path.join(root, file_name)\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "                    md5_hash.update(byte_block)\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "# Add MD5 checksum for each function based on rel_path\n",
    "for key, func_details in Params['function_dict'].items():\n",
    "    checksums = ''\n",
    "    path = func_details['rel_path']\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        # If the path is a directory, calculate MD5 for the whole directory\n",
    "        checksums = calculate_md5_for_folder(path)\n",
    "    elif os.path.isfile(path):\n",
    "        # If the path is a file, calculate MD5 for the file\n",
    "        checksums = calculate_md5_for_file(path)\n",
    "    else:\n",
    "        # Handle the case where the path is neither a file nor a directory\n",
    "        print(f\"Warning: This path is not a directory: {path}.\")\n",
    "\n",
    "    func_details['codebase_md5chsum'] = checksums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb9166-9c9b-4c3a-be85-a8b5bd2318b7",
   "metadata": {},
   "source": [
    "# Part 4.2: Generate_md5 checksums for records (Don't Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a834078d-2c0c-4092-9d61-8a19940bfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating MD5 for A0003.mat\n",
      "Generating MD5 for A0004.mat\n",
      "Generating MD5 for A0005.mat\n",
      "Generating MD5 for A0006.mat\n",
      "Generating MD5 for A0007.mat\n",
      "Generating MD5 for A0008.mat\n",
      "Generating MD5 for A0009.mat\n",
      "Generating MD5 for A0010.mat\n",
      "Generating MD5 for A0001.mat\n",
      "Generating MD5 for A0002.mat\n"
     ]
    }
   ],
   "source": [
    "def generate_md5_for_record(file_path, output_path):\n",
    "    # Create an MD5 hash object\n",
    "    hash_md5 = hashlib.md5()\n",
    "    \n",
    "    # Open the file in binary read mode\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Read the file in chunks of 4096 bytes\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            # Update the MD5 hash object with the chunk\n",
    "            hash_md5.update(chunk)\n",
    "    \n",
    "    # Get the hexadecimal representation of the MD5 hash\n",
    "    md5_hash = hash_md5.hexdigest()\n",
    "    \n",
    "    # Open the output file in write mode\n",
    "    with open(output_path, \"w\") as out_file:\n",
    "        # Write the MD5 hash to the output file\n",
    "        out_file.write(md5_hash)\n",
    "    \n",
    "    # Return the MD5 hash\n",
    "    return md5_hash\n",
    "\n",
    "def generate_md5_for_all_records_in_folder(input_folder_path, results_folder_path):\n",
    "\n",
    "    results_folder_path = results_folder_path + \"MD5_Checksum_records_python\"\n",
    "    \n",
    "    # Walk through the directory tree starting from input_folder_path\n",
    "    for root, dirs, files in os.walk(input_folder_path):\n",
    "        \n",
    "        # Compute the relative path from the input folder path\n",
    "        relative_path = os.path.relpath(root, input_folder_path)\n",
    "        \n",
    "        # Create corresponding folder in the results directory\n",
    "        result_folder = os.path.join(results_folder_path, relative_path)\n",
    "        os.makedirs(result_folder, exist_ok=True)\n",
    "        \n",
    "        # Iterate over all files in the current directory\n",
    "        for filename in files:\n",
    "            \n",
    "            # Check if the file has the desierd extension\n",
    "            if filename.endswith(data_endswith):\n",
    "                \n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                # Construct the output file path\n",
    "                output_path = os.path.join(result_folder, f\"MD5_{os.path.splitext(filename)[0]}.txt\")\n",
    "                \n",
    "                # Print the filename being processed\n",
    "                print(f\"Generating MD5 for {filename}\")\n",
    "                \n",
    "                # Generate the MD5 hash for the file and save it\n",
    "                generate_md5_for_record(file_path, output_path)\n",
    "\n",
    "generate_md5_for_all_records_in_folder(Data_Input_Path, Data_Output_Path)\n",
    "\n",
    "# List of MD5 checksum\n",
    "Input_MD5_list = []\n",
    "\n",
    "Input_MD5 = Data_Output_Path + \"MD5_Checksum_records_python\"\n",
    "\n",
    "# Walk through the directory tree starting from Data_Input_Path\n",
    "for root, dirs, files in os.walk(Input_MD5):\n",
    "    for file in files:\n",
    "        # Check if the file starts with 'MD5_' and ends with '.txt'\n",
    "        if file.startswith('MD5_') and file.endswith('.txt'):\n",
    "            \n",
    "            # Get the full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Get the file stats\n",
    "            file_stats = os.stat(file_path)\n",
    "            \n",
    "            # Append a dictionary to the list\n",
    "            Input_MD5_list.append({\n",
    "                'name': file,\n",
    "                'folder': root,\n",
    "            })\n",
    "Input_MD5_list = pd.DataFrame(Input_MD5_list)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fca059-49fb-4b6c-b273-1e25ca511d60",
   "metadata": {},
   "source": [
    "# Part 5: Feature Extraction (Don't Change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16715cf-c6bb-4cbf-bf12-355fc5523681",
   "metadata": {},
   "source": [
    "## Call the feature extraction function with the specified parameters\n",
    "#### - Input_Data_list: List of files to process\n",
    "#### - Params: Struct containing various parameters including sampling frequency, number of channels, and all input variables of the feature extraction functions\n",
    "#### - Data_Output_Path: Folder to save the results\n",
    "#### - Desired_Output_File: Name of the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578c3983-8245-403d-8b61-42e1fc497a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract feature for:\n",
      "A0003.mat\n",
      "A0004.mat\n",
      "A0005.mat\n",
      "A0006.mat\n",
      "A0007.mat\n",
      "A0008.mat\n",
      "A0009.mat\n",
      "A0010.mat\n",
      "A0001.mat\n",
      "A0002.mat\n"
     ]
    }
   ],
   "source": [
    "extract_feature(Input_Data_list, Input_MD5_list, Params, Data_Output_Path, Desired_Output_File)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
